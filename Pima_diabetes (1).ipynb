{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ch3Xq5iuGbBe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "pima=pd.read_csv(\"/content/diabetes.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pima.drop('Outcome',axis=1)\n",
        "y_train=pima['Outcome']\n",
        "print(X_train)\n",
        "print(y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92NHjbFZGhri",
        "outputId": "e07eb56a-852b-4a99-9ecc-652a634356af"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0              6      148             72             35        0  33.6   \n",
            "1              1       85             66             29        0  26.6   \n",
            "2              8      183             64              0        0  23.3   \n",
            "3              1       89             66             23       94  28.1   \n",
            "4              0      137             40             35      168  43.1   \n",
            "..           ...      ...            ...            ...      ...   ...   \n",
            "763           10      101             76             48      180  32.9   \n",
            "764            2      122             70             27        0  36.8   \n",
            "765            5      121             72             23      112  26.2   \n",
            "766            1      126             60              0        0  30.1   \n",
            "767            1       93             70             31        0  30.4   \n",
            "\n",
            "     DiabetesPedigreeFunction  Age  \n",
            "0                       0.627   50  \n",
            "1                       0.351   31  \n",
            "2                       0.672   32  \n",
            "3                       0.167   21  \n",
            "4                       2.288   33  \n",
            "..                        ...  ...  \n",
            "763                     0.171   63  \n",
            "764                     0.340   27  \n",
            "765                     0.245   30  \n",
            "766                     0.349   47  \n",
            "767                     0.315   23  \n",
            "\n",
            "[768 rows x 8 columns]\n",
            "0      1\n",
            "1      0\n",
            "2      1\n",
            "3      0\n",
            "4      1\n",
            "      ..\n",
            "763    0\n",
            "764    0\n",
            "765    0\n",
            "766    1\n",
            "767    0\n",
            "Name: Outcome, Length: 768, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train\",X_train.shape)\n",
        "print(\"y_train\",y_train.shape)\n",
        "print(X_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucZcbklGGjoM",
        "outputId": "bbd76de8-5689-4fb0-aa74-7ddec63aa25d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (768, 8)\n",
            "y_train (768,)\n",
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  \n",
            "0                     0.627   50  \n",
            "1                     0.351   31  \n",
            "2                     0.672   32  \n",
            "3                     0.167   21  \n",
            "4                     2.288   33  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: sigmoid\n",
        "import numpy as np\n",
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid of z\n",
        "\n",
        "    Args:\n",
        "        z (ndarray): A scalar, numpy array of any size.\n",
        "\n",
        "    Returns:\n",
        "        g (ndarray): sigmoid(z), with the same shape as z\n",
        "\n",
        "    \"\"\"\n",
        "    g = 1/(1+np.exp(-z))\n",
        "\n",
        "    return g"
      ],
      "metadata": {
        "id": "LxAcr9OQHCsO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute Cost\n",
        "def compute_cost(x,y,w,b):\n",
        "  m=x.shape[0]\n",
        "  cost = 0.0\n",
        "  for i in range(m):\n",
        "    z=np.dot(x[i],w)+b;\n",
        "    f_wb=sigmoid(z)\n",
        "    cost+=-y[i]*np.log(f_wb)-(1-y[i])*(np.log(1-f_wb))\n",
        "  total_cost=cost/m\n",
        "  return total_cost"
      ],
      "metadata": {
        "id": "ytILMlghHtBE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to compute gradient\n",
        "def compute_gradient(X, y, w, b):\n",
        "  \"\"\"\n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
        "      y : (ndarray Shape (m,))  target value\n",
        "      w : (ndarray Shape (n,))  values of parameters of the model\n",
        "      b : (scalar)              value of bias parameter of the model\n",
        "    Returns\n",
        "      dj_dw : (ndarray Shape (n,)) The gradient of the cost w.r.t. the parameters w.\n",
        "      dj_db : (scalar)             The gradient of the cost w.r.t. the parameter b.\n",
        "    \"\"\"\n",
        "  m, n = X.shape\n",
        "  dj_dw = np.zeros(w.shape)\n",
        "  dj_db = 0.\n",
        "\n",
        "  for i in range(m):\n",
        "    z_wb = np.dot(w,X[i]) + b\n",
        "\n",
        "    f_wb = sigmoid(z_wb)\n",
        "\n",
        "    for j in range(n):\n",
        "      dj_dw[j] = dj_dw[j] + (f_wb-y[i])*(X[i][j])\n",
        "    dj_db = dj_db + (f_wb-y[i])\n",
        "\n",
        "  dj_dw = dj_dw/m\n",
        "  dj_db = dj_db/m\n",
        "\n",
        "  return dj_dw, dj_db"
      ],
      "metadata": {
        "id": "RvLGWODFMIEU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w_in, b_in, cost_function, compute_gradient, alpha, num_iters):\n",
        "    \"\"\"\n",
        "    Performs batch gradient descent to learn theta. Updates theta by taking\n",
        "    num_iters gradient steps with learning rate alpha\n",
        "\n",
        "    Args:\n",
        "      X :    (ndarray Shape (m, n) data, m examples by n features\n",
        "      y :    (ndarray Shape (m,))  target value\n",
        "      w_in : (ndarray Shape (n,))  Initial values of parameters of the model\n",
        "      b_in : (scalar)              Initial value of parameter of the model\n",
        "      cost_function :              function to compute cost\n",
        "      gradient_function :          function to compute gradient\n",
        "      alpha : (float)              Learning rate\n",
        "      num_iters : (int)            number of iterations to run gradient descent\n",
        "    Returns:\n",
        "      w : (ndarray Shape (n,)) Updated values of parameters of the model after\n",
        "          running gradient descent\n",
        "      b : (scalar)                Updated value of parameter of the model after\n",
        "          running gradient descent\n",
        "    \"\"\"\n",
        "\n",
        "    # number of training examples\n",
        "    m = len(X)\n",
        "\n",
        "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
        "    J_history = []\n",
        "    w_history = []\n",
        "\n",
        "    for i in range(num_iters):\n",
        "\n",
        "        # Calculate the gradient and update the parameters\n",
        "        dj_dw, dj_db = compute_gradient(X, y, w_in, b_in)\n",
        "\n",
        "        # Update Parameters using w, b, alpha and gradient\n",
        "        w_in = w_in - alpha * dj_dw\n",
        "        b_in = b_in - alpha * dj_db\n",
        "\n",
        "        # Save cost J at each iteration\n",
        "        if i<100000:      # prevent resource exhaustion\n",
        "            cost =  cost_function(X, y, w_in, b_in)\n",
        "            J_history.append(cost)\n",
        "\n",
        "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
        "        if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1):\n",
        "            w_history.append(w_in)\n",
        "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
        "\n",
        "    return w_in, b_in, J_history, w_history #return w and J,w history for graphing"
      ],
      "metadata": {
        "id": "uBr7M4PfUWE9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "m, n = X_train.shape\n",
        "initial_w = 0.01 * (np.random.rand(n) - 0.5)\n",
        "initial_b = -8\n",
        "\n",
        "# Some gradient descent settings\n",
        "iterations = 10000\n",
        "alpha = 0.0001\n",
        "\n",
        "w,b, J_history,_ = gradient_descent(X_train.values ,y_train, initial_w, initial_b,\n",
        "                                   compute_cost, compute_gradient, alpha, iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk2MZZFQWary",
        "outputId": "14139cda-2420-4b06-b0be-6ff774458dc5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration    0: Cost     2.55   \n",
            "Iteration 1000: Cost     0.49   \n",
            "Iteration 2000: Cost     0.48   \n",
            "Iteration 3000: Cost     0.48   \n",
            "Iteration 4000: Cost     0.48   \n",
            "Iteration 5000: Cost     0.48   \n",
            "Iteration 6000: Cost     0.48   \n",
            "Iteration 7000: Cost     0.48   \n",
            "Iteration 8000: Cost     0.48   \n",
            "Iteration 9000: Cost     0.48   \n",
            "Iteration 9999: Cost     0.48   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "304f2365"
      },
      "source": [
        "# UNQ_C4\n",
        "# GRADED FUNCTION: predict\n",
        "\n",
        "def predict(X, w, b):\n",
        "    \"\"\"\n",
        "    Predict whether the label is 0 or 1 using learned logistic\n",
        "    regression parameters w\n",
        "\n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
        "      w : (ndarray Shape (n,))  values of parameters of the model\n",
        "      b : (scalar)              value of bias parameter of the model\n",
        "\n",
        "    Returns:\n",
        "      p : (ndarray (m,)) The predictions for X using a threshold at 0.5\n",
        "    \"\"\"\n",
        "    # number of training examples\n",
        "    m, n = X.shape\n",
        "    p = np.zeros(m)\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Loop over each example\n",
        "    for i in range(m):\n",
        "        z_wb = 0\n",
        "        # Loop over each feature\n",
        "        for j in range(n):\n",
        "            # Add the corresponding term to z_wb\n",
        "            z_wb += X[i, j] * w[j]\n",
        "\n",
        "        # Add bias term\n",
        "        z_wb += b\n",
        "\n",
        "        # Calculate the prediction for this example\n",
        "        f_wb = sigmoid(z_wb)\n",
        "\n",
        "        # Apply the threshold\n",
        "        p[i] = 1 if f_wb>0.5 else 0\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return p"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute accuracy on our training set\n",
        "p = predict(X_train.values, w,b)\n",
        "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMEmGWQUI-rL",
        "outputId": "86b1aec1-94eb-4051-a531-7e3435eb5d0f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 77.213542\n"
          ]
        }
      ]
    }
  ]
}