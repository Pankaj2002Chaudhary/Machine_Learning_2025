{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weBILK8d4lsm"
      },
      "source": [
        "Initialization and Regularization on Cat vs Non-cat Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pKGugDACe3w",
        "outputId": "565f0123-e793-4889-9b2b-df6477d9a896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/mscML2025_pankaj/Initialization')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe5Y8zla4W4Y"
      },
      "source": [
        "###Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iIayTCNhTFW6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "from init_utils import sigmoid, relu, compute_loss, forward_propagation, backward_propagation\n",
        "from init_utils import update_parameters, predict, load_cat_dataset, plot_decision_boundary, predict_dec\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# The load_cat_dataset function likely returns 5 values (including classes)\n",
        "train_X, train_Y, test_X, test_Y, classes = load_cat_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ha4dKgJaTFKk"
      },
      "outputs": [],
      "source": [
        "def model(X, Y, learning_rate = 0.01, num_iterations = 15000, print_cost = True, initialization = \"he\"):\n",
        "    \"\"\"\n",
        "    Implements a three-layer neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SIGMOID.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data, of shape (2, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 for red dots; 1 for blue dots), of shape (1, number of examples)\n",
        "    learning_rate -- learning rate for gradient descent\n",
        "    num_iterations -- number of iterations to run gradient descent\n",
        "    print_cost -- if True, print the cost every 1000 iterations\n",
        "    initialization -- flag to choose which initialization to use (\"zeros\",\"random\" or \"he\")\n",
        "\n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model\n",
        "    \"\"\"\n",
        "\n",
        "    grads = {}\n",
        "    costs = [] # to keep track of the loss\n",
        "    m = X.shape[1] # number of examples\n",
        "    layers_dims = [X.shape[0], 10, 5, 1]\n",
        "\n",
        "    # Initialize parameters dictionary.\n",
        "    if initialization == \"zeros\":\n",
        "        parameters = initialize_parameters_zeros(layers_dims)\n",
        "    elif initialization == \"random\":\n",
        "        parameters = initialize_parameters_random(layers_dims)\n",
        "    elif initialization == \"he\":\n",
        "        parameters = initialize_parameters_he(layers_dims)\n",
        "\n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID.\n",
        "        a3, cache = forward_propagation(X, parameters)\n",
        "\n",
        "        # Loss\n",
        "        cost = compute_loss(a3, Y)\n",
        "\n",
        "        # Backward propagation.\n",
        "        grads = backward_propagation(X, Y, cache)\n",
        "\n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        # Print the loss every 1000 iterations\n",
        "        if print_cost and i % 1000 == 0:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
        "            costs.append(cost)\n",
        "\n",
        "    # plot the loss\n",
        "    plt.plot(costs)\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yLbNlN7TgcU"
      },
      "source": [
        "###Zero initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HIbKBYSeTY3n"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: initialize_parameters_zeros\n",
        "\n",
        "def initialize_parameters_zeros(layers_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the size of each layer.\n",
        "\n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
        "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
        "                    ...\n",
        "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
        "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
        "    \"\"\"\n",
        "\n",
        "    parameters = {}\n",
        "    L = len(layers_dims)            # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.zeros((layers_dims[l], layers_dims[l-1]))\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_g3qiiPTvH9",
        "outputId": "6d5c58a9-37db-4f6e-c70a-091792fbb0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 = [[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "b1 = [[0.]\n",
            " [0.]]\n",
            "W2 = [[0. 0.]]\n",
            "b2 = [[0.]]\n"
          ]
        }
      ],
      "source": [
        "parameters = initialize_parameters_zeros([3,2,1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = model(train_X, train_Y, initialization = \"zeros\")\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "memG_rHOLuYT",
        "outputId": "cd4d82c0-5f5b-460f-84fb-5811bf588ae3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.6931471805599453\n",
            "Cost after iteration 1000: 0.6444151571406833\n",
            "Cost after iteration 2000: 0.6439784295472034\n",
            "Cost after iteration 3000: 0.6439737889407632\n",
            "Cost after iteration 4000: 0.6439737386059642\n",
            "Cost after iteration 5000: 0.6439737380588201\n",
            "Cost after iteration 6000: 0.6439737380528714\n",
            "Cost after iteration 7000: 0.6439737380528066\n",
            "Cost after iteration 8000: 0.6439737380528056\n",
            "Cost after iteration 9000: 0.6439737380528059\n",
            "Cost after iteration 10000: 0.6439737380528057\n",
            "Cost after iteration 11000: 0.6439737380528056\n",
            "Cost after iteration 12000: 0.6439737380528059\n",
            "Cost after iteration 13000: 0.6439737380528059\n",
            "Cost after iteration 14000: 0.6439737380528059\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the train set:\n",
            "Accuracy: 0.6555023923444976\n",
            "On the test set:\n",
            "Accuracy: 0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fomf97gBYH4z",
        "outputId": "68a83962-7085-4722-e771-13261e90f78d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions_train = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "predictions_test = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print (\"predictions_train = \" + str(predictions_train))\n",
        "print (\"predictions_test = \" + str(predictions_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SRZMHi-ZIEz"
      },
      "source": [
        "###Random initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GjdfDUVeV8n6"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: initialize_parameters_random\n",
        "\n",
        "def initialize_parameters_random(layers_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the size of each layer.\n",
        "\n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
        "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
        "                    ...\n",
        "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
        "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(3)               # This seed makes sure your \"random\" numbers will be the as ours\n",
        "    parameters = {}\n",
        "    L = len(layers_dims)            # integer representing the number of layers\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1])*10\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
        "\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-pK1LrTWttH",
        "outputId": "cb22eb0d-8876-4d5d-fab7-75420375f6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 = [[ 17.88628473   4.36509851   0.96497468]\n",
            " [-18.63492703  -2.77388203  -3.54758979]]\n",
            "b1 = [[0.]\n",
            " [0.]]\n",
            "W2 = [[-0.82741481 -6.27000677]]\n",
            "b2 = [[0.]]\n"
          ]
        }
      ],
      "source": [
        "parameters = initialize_parameters_random([3, 2, 1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngjQhVajWuBX",
        "outputId": "b0026d87-8994-4d12-874c-740b56eb27e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/mscML2025_pankaj/Initialization/init_utils.py:17: RuntimeWarning: overflow encountered in exp\n",
            "  s = 1/(1+np.exp(-x))\n",
            "/content/drive/MyDrive/mscML2025_pankaj/Initialization/init_utils.py:145: RuntimeWarning: divide by zero encountered in log\n",
            "  logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)\n",
            "/content/drive/MyDrive/mscML2025_pankaj/Initialization/init_utils.py:145: RuntimeWarning: invalid value encountered in multiply\n",
            "  logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 1000: 0.6229575088636773\n",
            "Cost after iteration 2000: 0.622482936925185\n",
            "Cost after iteration 3000: 0.6224771595865887\n",
            "Cost after iteration 4000: 0.6224770815313617\n",
            "Cost after iteration 5000: 0.6224770742294082\n",
            "Cost after iteration 6000: 0.6224770678617507\n",
            "Cost after iteration 7000: 0.6224770615596321\n"
          ]
        }
      ],
      "source": [
        "parameters = model(train_X, train_Y, initialization = \"random\")\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01Nq_KAiXY40"
      },
      "outputs": [],
      "source": [
        "print (predictions_train)\n",
        "print (predictions_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JylWxifZMxp"
      },
      "source": [
        "###He initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0QI-nS6YNXq"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters_he(layers_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the size of each layer.\n",
        "\n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
        "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
        "                    ...\n",
        "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
        "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(3)\n",
        "    parameters = {}\n",
        "    L = len(layers_dims) - 1  # number of layers\n",
        "\n",
        "    for l in range(1, L + 1):\n",
        "        parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * np.sqrt(2. / layers_dims[l - 1])\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
        "\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E1OiU-lYE3S"
      },
      "outputs": [],
      "source": [
        "parameters = initialize_parameters_he([2, 4, 1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9kUrhClYWXy"
      },
      "outputs": [],
      "source": [
        "parameters = model(train_X, train_Y, initialization = \"he\")\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9XhQvNvaaGk"
      },
      "source": [
        "</tr>\n",
        "    <td>\n",
        "    3-layer NN with zeros initialization - 34%\n",
        "    </td>\n",
        "<tr>\n",
        "    <td>\n",
        "    3-layer NN with large random initialization - 34%\n",
        "    </td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\n",
        "    3-layer NN with He initialization - 76%\n",
        "    </td>\n",
        "    <td>\n",
        "    recommended method\n",
        "    </td>\n",
        "</tr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTL_yFAVbp-U"
      },
      "source": [
        "###Regularization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Regularization on He_Initialized model\n"
      ],
      "metadata": {
        "id": "5IvRRU7TYfDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, sys, numpy as np, h5py, matplotlib.pyplot as plt\n",
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/Initialization'\n",
        "sys.path.append(base_dir)\n",
        "\n",
        "from init_utils import sigmoid, relu, compute_loss, predict\n",
        "from reg_utils import forward_propagation, backward_propagation, update_parameters\n",
        "\n",
        "#load cat vs non-cat dataset\n",
        "def load_cat_dataset_from_drive(base_dir):\n",
        "    train_path = os.path.join(base_dir, 'train_catvnoncat.h5')\n",
        "    test_path  = os.path.join(base_dir, 'test_catvnoncat.h5')\n",
        "    train_dataset = h5py.File(train_path, \"r\")\n",
        "    test_dataset  = h5py.File(test_path, \"r\")\n",
        "    train_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "    train_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
        "    test_x_orig  = np.array(test_dataset[\"test_set_x\"][:])\n",
        "    test_y_orig  = np.array(test_dataset[\"test_set_y\"][:])\n",
        "    train_x = train_x_orig.reshape(train_x_orig.shape[0], -1).T / 255.\n",
        "    test_x  = test_x_orig.reshape(test_x_orig.shape[0], -1).T / 255.\n",
        "    train_y = train_y_orig.reshape(1, train_y_orig.shape[0])\n",
        "    test_y  = test_y_orig.reshape(1, test_y_orig.shape[0])\n",
        "    return train_x, train_y, test_x, test_y\n",
        "\n",
        "train_X, train_Y, test_X, test_Y = load_cat_dataset_from_drive(base_dir)\n",
        "print(\"Loaded shapes:\", train_X.shape, train_Y.shape, test_X.shape, test_Y.shape)\n",
        "\n",
        "# He Initialization\n",
        "\n",
        "def initialize_parameters_he(layers_dims):\n",
        "    np.random.seed(3)\n",
        "    parameters = {}\n",
        "    L = len(layers_dims)\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1]) * np.sqrt(2. / layers_dims[l-1])\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
        "    return parameters\n",
        "\n",
        "# L2 Regularization\n",
        "def compute_cost_with_regularization(A3, Y, parameters, lambd):\n",
        "    m = Y.shape[1]\n",
        "    W1, W2, W3 = parameters[\"W1\"], parameters[\"W2\"], parameters[\"W3\"]\n",
        "    cross_entropy_cost = compute_loss(A3, Y)\n",
        "    L2_regularization_cost = (lambd/(2*m))*(np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)))\n",
        "    return cross_entropy_cost + L2_regularization_cost\n",
        "\n",
        "def backward_propagation_with_regularization(X, Y, cache, lambd):\n",
        "    m = X.shape[1]\n",
        "    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache\n",
        "    dZ3 = A3 - Y\n",
        "    dW3 = (1/m)*np.dot(dZ3, A2.T) + (lambd/m)*W3\n",
        "    db3 = (1/m)*np.sum(dZ3, axis=1, keepdims=True)\n",
        "    dA2 = np.dot(W3.T, dZ3)\n",
        "    dZ2 = np.multiply(dA2, np.int64(A2 > 0))\n",
        "    dW2 = (1/m)*np.dot(dZ2, A1.T) + (lambd/m)*W2\n",
        "    db2 = (1/m)*np.sum(dZ2, axis=1, keepdims=True)\n",
        "    dA1 = np.dot(W2.T, dZ2)\n",
        "    dZ1 = np.multiply(dA1, np.int64(A1 > 0))\n",
        "    dW1 = (1/m)*np.dot(dZ1, X.T) + (lambd/m)*W1\n",
        "    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)\n",
        "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2, \"dW3\": dW3, \"db3\": db3}\n",
        "    return grads\n",
        "\n",
        "# Dropout Regularization\n",
        "def forward_propagation_with_dropout(X, parameters, keep_prob=0.8):\n",
        "    np.random.seed(1)\n",
        "    W1, b1 = parameters[\"W1\"], parameters[\"b1\"]\n",
        "    W2, b2 = parameters[\"W2\"], parameters[\"b2\"]\n",
        "    W3, b3 = parameters[\"W3\"], parameters[\"b3\"]\n",
        "\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = relu(Z1)\n",
        "    D1 = np.random.rand(A1.shape[0], A1.shape[1]) < keep_prob\n",
        "    A1 = (A1 * D1) / keep_prob\n",
        "\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = relu(Z2)\n",
        "    D2 = np.random.rand(A2.shape[0], A2.shape[1]) < keep_prob\n",
        "    A2 = (A2 * D2) / keep_prob\n",
        "\n",
        "    Z3 = np.dot(W3, A2) + b3\n",
        "    A3 = sigmoid(Z3)\n",
        "\n",
        "    cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3)\n",
        "    return A3, cache\n",
        "\n",
        "def backward_propagation_with_dropout(X, Y, cache, keep_prob):\n",
        "    m = X.shape[1]\n",
        "    (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache\n",
        "    dZ3 = A3 - Y\n",
        "    dW3 = (1/m)*np.dot(dZ3, A2.T)\n",
        "    db3 = (1/m)*np.sum(dZ3, axis=1, keepdims=True)\n",
        "    dA2 = np.dot(W3.T, dZ3) * D2 / keep_prob\n",
        "    dZ2 = np.multiply(dA2, np.int64(A2 > 0))\n",
        "    dW2 = (1/m)*np.dot(dZ2, A1.T)\n",
        "    db2 = (1/m)*np.sum(dZ2, axis=1, keepdims=True)\n",
        "    dA1 = np.dot(W2.T, dZ2) * D1 / keep_prob\n",
        "    dZ1 = np.multiply(dA1, np.int64(A1 > 0))\n",
        "    dW1 = (1/m)*np.dot(dZ1, X.T)\n",
        "    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)\n",
        "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2, \"dW3\": dW3, \"db3\": db3}\n",
        "    return grads\n",
        "\n",
        "# Train He-Initialized Model\n",
        "def model(X, Y, layers_dims, reg_type=None, lambd=0, keep_prob=1.0, learning_rate=0.0075, num_iterations=10000):\n",
        "    parameters = initialize_parameters_he(layers_dims)\n",
        "    costs = []\n",
        "    for i in range(num_iterations):\n",
        "        if reg_type == \"dropout\":\n",
        "            A3, cache = forward_propagation_with_dropout(X, parameters, keep_prob)\n",
        "            cost = compute_loss(A3, Y)\n",
        "            grads = backward_propagation_with_dropout(X, Y, cache, keep_prob)\n",
        "        else:\n",
        "            A3, cache = forward_propagation(X, parameters)\n",
        "            if reg_type == \"l2\":\n",
        "                cost = compute_cost_with_regularization(A3, Y, parameters, lambd)\n",
        "                grads = backward_propagation_with_regularization(X, Y, cache, lambd)\n",
        "            else:\n",
        "                cost = compute_loss(A3, Y)\n",
        "                grads = backward_propagation(X, Y, cache)\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        if i % 1000 == 0:\n",
        "            costs.append(cost)\n",
        "            print(f\"Iter {i}: Cost = {cost:.5f}\")\n",
        "    return parameters, costs\n",
        "\n",
        "# Run models with He initialization + Regularization\n",
        "layers_dims = [train_X.shape[0], 10, 5, 1]\n",
        "\n",
        "print(\"\\n He Initialization (no regularization)\")\n",
        "params_he, cost_he = model(train_X, train_Y, layers_dims)\n",
        "\n",
        "print(\"\\n He + L2 Regularization (=0.7)\")\n",
        "params_l2, cost_l2 = model(train_X, train_Y, layers_dims, reg_type=\"l2\", lambd=0.7)\n",
        "\n",
        "print(\"\\n He + Dropout (keep_prob=0.8)\")\n",
        "params_drop, cost_drop = model(train_X, train_Y, layers_dims, reg_type=\"dropout\", keep_prob=0.8)\n",
        "\n",
        "# Compare Cost Curves\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(cost_he, label=\"He Initialization\")\n",
        "plt.plot(cost_l2, label=\"He + L2 Regularization\")\n",
        "plt.plot(cost_drop, label=\"He + Dropout\")\n",
        "plt.xlabel(\"Iterations (1000)\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.title(\"He Initialization vs Regularization (Cat vs Non-Cat)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\n=== Accuracy Comparison ===\")\n",
        "print(\"\\nHe Initialization:\")\n",
        "predict(train_X, train_Y, params_he)\n",
        "predict(test_X, test_Y, params_he)\n",
        "\n",
        "print(\"\\nHe + L2 Regularization:\")\n",
        "predict(train_X, train_Y, params_l2)\n",
        "predict(test_X, test_Y, params_l2)\n",
        "\n",
        "print(\"\\nHe + Dropout:\")\n",
        "predict(train_X, train_Y, params_drop)\n",
        "predict(test_X, test_Y, params_drop)\n"
      ],
      "metadata": {
        "id": "jCJwNRvVNlVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FEMLAknWTn2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}